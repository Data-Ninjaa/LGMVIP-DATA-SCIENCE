{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233f2d26",
   "metadata": {},
   "source": [
    "# Haleema Sadia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba612c42",
   "metadata": {},
   "source": [
    "# Task 8 Next Word Prediction Using RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d80c5c",
   "metadata": {},
   "source": [
    "# LGMVIP DATA SCIENCE INTERNSHIP JULY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ea11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout,LSTM,Embedding\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11588dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data = open(\"1661-0.txt\",'r',encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959ad8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\n",
      "Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.net\n",
      "\n",
      "\n",
      "Title: The Adventures of Sherlock Holmes\n",
      "\n",
      "Author: Arthur Conan Doyle\n",
      "\n",
      "Release Date: November 29, 2002 [EBook #1661]\n",
      "Last Updated: May 20, 2019\n",
      "\n",
      "Language: English\n",
      "\n",
      "Charac\n"
     ]
    }
   ],
   "source": [
    "print(data[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce107b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all characters to lower case\n",
    "data = data.lower()\n",
    "#removing any digits if the data has\n",
    "data = ''.join(ch for ch in data if not ch.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10800e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\n",
      "project gutenberg's the adventures of sherlock holmes, by arthur conan doyle\n",
      "\n",
      "this ebook is for th\n"
     ]
    }
   ],
   "source": [
    "print(data[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6eb50a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Characters in data are:  63\n",
      "{'q', 'é', ',', 'g', 'y', '(', '½', '[', 'c', 'i', ':', 'à', ';', '%', '\"', 'l', ']', 'o', 'p', '*', 'a', ')', '“', 'u', 'x', 'n', 'z', 'f', 'd', '‘', '?', 'm', 'w', '-', '’', '”', '#', '/', '_', 'è', '\\n', 'k', '!', 't', ' ', \"'\", 'e', 'œ', '@', '$', 'j', '\\ufeff', 'v', 's', 'r', 'h', '—', '&', 'æ', '£', 'b', '.', 'â'}\n"
     ]
    }
   ],
   "source": [
    "chars = set(data)\n",
    "vocab = len(chars)\n",
    "print(\"Number of Unique Characters in data are: \",vocab)\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9796d46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters in Data, corpus length:  581397\n"
     ]
    }
   ],
   "source": [
    "#length of data\n",
    "print(\"Total Characters in Data, corpus length: \",len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8959b1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "project gutenbergs the adventures of sherlock holmes by arthur conan doyle\n",
      "\n",
      "this ebook is for the u\n"
     ]
    }
   ],
   "source": [
    "#if you want you can remove special characters from data the code is given below. This is optionsl.\n",
    "data = ''.join(char for char in data if char.isalnum() or char.isspace())\n",
    "print(data[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f079d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters to Integers:\n",
      " {'q': 0, 'é': 1, ',': 2, 'g': 3, 'y': 4, '(': 5, '½': 6, '[': 7, 'c': 8, 'i': 9, ':': 10, 'à': 11, ';': 12, '%': 13, '\"': 14, 'l': 15, ']': 16, 'o': 17, 'p': 18, '*': 19, 'a': 20, ')': 21, '“': 22, 'u': 23, 'x': 24, 'n': 25, 'z': 26, 'f': 27, 'd': 28, '‘': 29, '?': 30, 'm': 31, 'w': 32, '-': 33, '’': 34, '”': 35, '#': 36, '/': 37, '_': 38, 'è': 39, '\\n': 40, 'k': 41, '!': 42, 't': 43, ' ': 44, \"'\": 45, 'e': 46, 'œ': 47, '@': 48, '$': 49, 'j': 50, '\\ufeff': 51, 'v': 52, 's': 53, 'r': 54, 'h': 55, '—': 56, '&': 57, 'æ': 58, '£': 59, 'b': 60, '.': 61, 'â': 62} \n",
      "\n",
      "Integers to Characters:\n",
      " {0: 'q', 1: 'é', 2: ',', 3: 'g', 4: 'y', 5: '(', 6: '½', 7: '[', 8: 'c', 9: 'i', 10: ':', 11: 'à', 12: ';', 13: '%', 14: '\"', 15: 'l', 16: ']', 17: 'o', 18: 'p', 19: '*', 20: 'a', 21: ')', 22: '“', 23: 'u', 24: 'x', 25: 'n', 26: 'z', 27: 'f', 28: 'd', 29: '‘', 30: '?', 31: 'm', 32: 'w', 33: '-', 34: '’', 35: '”', 36: '#', 37: '/', 38: '_', 39: 'è', 40: '\\n', 41: 'k', 42: '!', 43: 't', 44: ' ', 45: \"'\", 46: 'e', 47: 'œ', 48: '@', 49: '$', 50: 'j', 51: '\\ufeff', 52: 'v', 53: 's', 54: 'r', 55: 'h', 56: '—', 57: '&', 58: 'æ', 59: '£', 60: 'b', 61: '.', 62: 'â'}\n"
     ]
    }
   ],
   "source": [
    "#convert characters to integer for training\n",
    "ch_to_int = dict((c,i)for i,c in enumerate(chars))\n",
    "print(\"Characters to Integers:\\n\",ch_to_int,\"\\n\")\n",
    "#convert integer to characters \n",
    "int_to_ch = dict((i,c)for i,c in enumerate(chars))\n",
    "print(\"Integers to Characters:\\n\",int_to_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbb4dd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#lets print a integer mapping for a \n",
    "print(ch_to_int.get('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb7f0690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenbergs', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'by', 'arthur', 'conan', 'doyle', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 'reuse', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'wwwgutenbergnet', 'title', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'author', 'arthur', 'conan', 'doyle', 'release', 'date', 'november', 'ebook', 'last', 'updated', 'may', 'language', 'english', 'character', 'set', 'encoding', 'utf', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'produced', 'by', 'an', 'anonymous', 'project', 'gutenberg', 'volunteer', 'and', 'jose', 'menendez', 'cover']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the data into words and non-word characters\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(data)\n",
    "print(tokens[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ae9b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens in data are:  8602\n",
      "Number of times 'the' used in data is:  7566\n"
     ]
    }
   ],
   "source": [
    "#counting how many times each word is used.\n",
    "unique_tokens = np.unique(tokens)\n",
    "print(\"Number of unique tokens in data are: \",len(unique_tokens))\n",
    "unique_token_index = dict((c, i) for i, c in enumerate(unique_tokens))\n",
    "print(\"Number of times 'the' used in data is: \",unique_token_index.get(\"the\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59281f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences are:  35809\n"
     ]
    }
   ],
   "source": [
    "#sequence length is set to 3\n",
    "sequence_length = 5\n",
    "#skip few tokens in the data\n",
    "step = 3\n",
    "#maintianing an array of previous and next tokens\n",
    "previous_token =[]\n",
    "next_token=[]\n",
    "# iterating through tokens \n",
    "for i in range(0,len(tokens)-sequence_length,step):\n",
    "    #appending in previous and next tokens\n",
    "    previous_token.append(tokens[i:i+sequence_length])\n",
    "    next_token.append(tokens[i+sequence_length])\n",
    "#Number of sequence \n",
    "n_sequence = len(previous_token)\n",
    "print(\"Number of sequences are: \",n_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba228278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sherlock', 'arthur', 'this', 'for', 'of', 'at', 'and', 'no', 'you', 'it', 'away', 'it', 'terms', 'project', 'included', 'ebook', 'at', 'the', 'sherlock', 'arthur', 'release', 'ebook', 'may', 'character', 'utf', 'this', 'ebook', 'of', 'produced', 'anonymous', 'volunteer', 'menendez', 'adventures', 'holmes', 'conan', 'i', 'in', 'the', 'iii', 'of', 'the', 'mystery', 'five', 'vi', 'with', 'lip', 'adventure', 'blue', 'the', 'the', 'ix', 'of', 'thumb', 'adventure', 'noble', 'the', 'the', 'xii', 'of', 'beeches', 'scandal', 'i', 'holmes', 'always', 'i', 'heard', 'her', 'other', 'his', 'eclipses', 'the', 'her', 'was', 'he', 'emotion', 'love', 'adler', 'and', 'particularly', 'to', 'precise', 'balanced', 'was', 'it', 'perfect', 'observing', 'the', 'seen', 'a', 'would', 'himself', 'false', 'never', 'the', 'save', 'gibe', 'sneer', 'admirable', 'the', 'drawing']\n"
     ]
    }
   ],
   "source": [
    "print(next_token[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b077ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['project', 'gutenbergs', 'the', 'adventures', 'of'], ['adventures', 'of', 'sherlock', 'holmes', 'by'], ['holmes', 'by', 'arthur', 'conan', 'doyle'], ['conan', 'doyle', 'this', 'ebook', 'is'], ['ebook', 'is', 'for', 'the', 'use'], ['the', 'use', 'of', 'anyone', 'anywhere'], ['anyone', 'anywhere', 'at', 'no', 'cost'], ['no', 'cost', 'and', 'with', 'almost'], ['with', 'almost', 'no', 'restrictions', 'whatsoever'], ['restrictions', 'whatsoever', 'you', 'may', 'copy'], ['may', 'copy', 'it', 'give', 'it'], ['give', 'it', 'away', 'or', 'reuse'], ['or', 'reuse', 'it', 'under', 'the'], ['under', 'the', 'terms', 'of', 'the'], ['of', 'the', 'project', 'gutenberg', 'license'], ['gutenberg', 'license', 'included', 'with', 'this'], ['with', 'this', 'ebook', 'or', 'online'], ['or', 'online', 'at', 'wwwgutenbergnet', 'title'], ['wwwgutenbergnet', 'title', 'the', 'adventures', 'of'], ['adventures', 'of', 'sherlock', 'holmes', 'author'], ['holmes', 'author', 'arthur', 'conan', 'doyle'], ['conan', 'doyle', 'release', 'date', 'november'], ['date', 'november', 'ebook', 'last', 'updated'], ['last', 'updated', 'may', 'language', 'english'], ['language', 'english', 'character', 'set', 'encoding'], ['set', 'encoding', 'utf', 'start', 'of'], ['start', 'of', 'this', 'project', 'gutenberg'], ['project', 'gutenberg', 'ebook', 'the', 'adventures'], ['the', 'adventures', 'of', 'sherlock', 'holmes'], ['sherlock', 'holmes', 'produced', 'by', 'an'], ['by', 'an', 'anonymous', 'project', 'gutenberg'], ['project', 'gutenberg', 'volunteer', 'and', 'jose'], ['and', 'jose', 'menendez', 'cover', 'the'], ['cover', 'the', 'adventures', 'of', 'sherlock'], ['of', 'sherlock', 'holmes', 'by', 'arthur'], ['by', 'arthur', 'conan', 'doyle', 'contents'], ['doyle', 'contents', 'i', 'a', 'scandal'], ['a', 'scandal', 'in', 'bohemia', 'ii'], ['bohemia', 'ii', 'the', 'redheaded', 'league'], ['redheaded', 'league', 'iii', 'a', 'case'], ['a', 'case', 'of', 'identity', 'iv'], ['identity', 'iv', 'the', 'boscombe', 'valley'], ['boscombe', 'valley', 'mystery', 'v', 'the'], ['v', 'the', 'five', 'orange', 'pips'], ['orange', 'pips', 'vi', 'the', 'man'], ['the', 'man', 'with', 'the', 'twisted'], ['the', 'twisted', 'lip', 'vii', 'the'], ['vii', 'the', 'adventure', 'of', 'the'], ['of', 'the', 'blue', 'carbuncle', 'viii'], ['carbuncle', 'viii', 'the', 'adventure', 'of'], ['adventure', 'of', 'the', 'speckled', 'band'], ['speckled', 'band', 'ix', 'the', 'adventure'], ['the', 'adventure', 'of', 'the', 'engineers'], ['the', 'engineers', 'thumb', 'x', 'the'], ['x', 'the', 'adventure', 'of', 'the'], ['of', 'the', 'noble', 'bachelor', 'xi'], ['bachelor', 'xi', 'the', 'adventure', 'of'], ['adventure', 'of', 'the', 'beryl', 'coronet'], ['beryl', 'coronet', 'xii', 'the', 'adventure'], ['the', 'adventure', 'of', 'the', 'copper'], ['the', 'copper', 'beeches', 'i', 'a'], ['i', 'a', 'scandal', 'in', 'bohemia'], ['in', 'bohemia', 'i', 'to', 'sherlock'], ['to', 'sherlock', 'holmes', 'she', 'is'], ['she', 'is', 'always', 'the', 'woman'], ['the', 'woman', 'i', 'have', 'seldom'], ['have', 'seldom', 'heard', 'him', 'mention'], ['him', 'mention', 'her', 'under', 'any'], ['under', 'any', 'other', 'name', 'in'], ['name', 'in', 'his', 'eyes', 'she'], ['eyes', 'she', 'eclipses', 'and', 'predominates'], ['and', 'predominates', 'the', 'whole', 'of'], ['whole', 'of', 'her', 'sex', 'it'], ['sex', 'it', 'was', 'not', 'that'], ['not', 'that', 'he', 'felt', 'any'], ['felt', 'any', 'emotion', 'akin', 'to'], ['akin', 'to', 'love', 'for', 'irene'], ['for', 'irene', 'adler', 'all', 'emotions'], ['all', 'emotions', 'and', 'that', 'one'], ['that', 'one', 'particularly', 'were', 'abhorrent'], ['were', 'abhorrent', 'to', 'his', 'cold'], ['his', 'cold', 'precise', 'but', 'admirably'], ['but', 'admirably', 'balanced', 'mind', 'he'], ['mind', 'he', 'was', 'i', 'take'], ['i', 'take', 'it', 'the', 'most'], ['the', 'most', 'perfect', 'reasoning', 'and'], ['reasoning', 'and', 'observing', 'machine', 'that'], ['machine', 'that', 'the', 'world', 'has'], ['world', 'has', 'seen', 'but', 'as'], ['but', 'as', 'a', 'lover', 'he'], ['lover', 'he', 'would', 'have', 'placed'], ['have', 'placed', 'himself', 'in', 'a'], ['in', 'a', 'false', 'position', 'he'], ['position', 'he', 'never', 'spoke', 'of'], ['spoke', 'of', 'the', 'softer', 'passions'], ['softer', 'passions', 'save', 'with', 'a'], ['with', 'a', 'gibe', 'and', 'a'], ['and', 'a', 'sneer', 'they', 'were'], ['they', 'were', 'admirable', 'things', 'for'], ['things', 'for', 'the', 'observerexcellent', 'for']]\n"
     ]
    }
   ],
   "source": [
    "print(previous_token[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "722f62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing the data\n",
    "#creating an array filled with 0s\n",
    "X = np.zeros((len(previous_token), sequence_length, len(unique_tokens)), dtype=bool)\n",
    "#creating an array filled with 0s\n",
    "Y = np.zeros((len(next_token), len(unique_tokens)), dtype=bool)\n",
    "#iterating through previous token to fill the array with true and false values respectively.\n",
    "for i, each_tokens in enumerate(previous_token):\n",
    "    for j, each_token in enumerate(each_tokens):\n",
    "        X[i, j, unique_token_index[each_token]] = 1\n",
    "    Y[i, unique_token_index[next_token[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74ca67c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35809, 5, 8602)\n",
      "(35809, 8602)\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Y[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19aa5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape = (sequence_length,X.shape[2])))\n",
    "model.add(Dense(len(unique_tokens), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a925ba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 128)               4470272   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8602)              1109658   \n",
      "=================================================================\n",
      "Total params: 5,579,930\n",
      "Trainable params: 5,579,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a08100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "280/280 [==============================] - 65s 224ms/step - loss: 6.9205 - accuracy: 0.0533\n",
      "Epoch 2/8\n",
      "280/280 [==============================] - 57s 204ms/step - loss: 6.3255 - accuracy: 0.0541\n",
      "Epoch 3/8\n",
      "133/280 [=============>................] - ETA: 29s - loss: 6.2742 - accuracy: 0.0523"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "history = model.fit(X,Y, epochs = 8 ,batch_size = 128,verbose =1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858660c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = history['loss']\n",
    "accuracy_values = history['accuracy']\n",
    "print(\"Accuracy: \",accuracy_values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_values)\n",
    "plt.plot(accuracy_values)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021684a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, sequence_length, len(unique_tokens)))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        print(word)\n",
    "        x[0, t, unique_token_index[word]] = 1\n",
    "    return x\n",
    "prepare_input(\"It is not a the\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    print(\"in sample\")\n",
    "\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e91d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completion(text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        print(\"in predic completeion\")\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        \n",
    "        \n",
    "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
    "            print(\"retrurning in predic completeion\")\n",
    "            return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6535be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completions(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    print(\"next indices is: \",next_indices)\n",
    "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = data[170:210]\n",
    "print(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "def prepare_input(text):\n",
    "    x = np.zeros((1, sequence_length, len(unique_tokens)))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        x[0, t, unique_token_index[word]] = 1\n",
    "    return x\n",
    "\n",
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
    "\n",
    "def predict_completion(text, max_length=100):  # Add max_length argument\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    while len(original_text + completion) < max_length:  # Check max_length\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        if next_char == ' ':  # Break if space character is predicted\n",
    "            break\n",
    "    return completion\n",
    "\n",
    "def predict_completions(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]\n",
    "\n",
    "# Assuming 'quotes' is defined as a list of strings, e.g., ['quote1', 'quote2', ...]\n",
    "for q in quotes:\n",
    "    seq = q[:40].lower()\n",
    "    print(\"SEQ is: \", seq)\n",
    "    print(predict_completions(seq, 5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
